import store from '@renderer/store'
import { selectCurrentUserId, selectGlobalMemoryEnabled, selectMemoryConfig } from '@renderer/store/memory'
import type { Assistant } from '@renderer/types'
import { type InferToolInput, type InferToolOutput, tool } from 'ai'
import { z } from 'zod'

import { MemoryProcessor } from '../../services/MemoryProcessor'

/**
 * ðŸ§  åŸºç¡€è®°å¿†æœç´¢å·¥å…·
 * AI å¯ä»¥ä¸»åŠ¨è°ƒç”¨çš„ç®€å•è®°å¿†æœç´¢
 */
export const memorySearchTool = () => {
  return tool({
    name: 'builtin_memory_search',
    description: 'Search through conversation memories and stored facts for relevant context',
    inputSchema: z.object({
      query: z.string().describe('Search query to find relevant memories'),
      limit: z.number().min(1).max(20).default(5).describe('Maximum number of memories to return')
    }),
    execute: async ({ query, limit = 5 }) => {
      // console.log('ðŸ§  [memorySearchTool] Searching memories:', { query, limit })

      try {
        const globalMemoryEnabled = selectGlobalMemoryEnabled(store.getState())
        if (!globalMemoryEnabled) {
          return []
        }

        const memoryConfig = selectMemoryConfig(store.getState())
        if (!memoryConfig.llmApiClient || !memoryConfig.embedderApiClient) {
          // console.warn('Memory search skipped: embedding or LLM model not configured')
          return []
        }

        const currentUserId = selectCurrentUserId(store.getState())
        const processorConfig = MemoryProcessor.getProcessorConfig(memoryConfig, 'default', currentUserId)

        const memoryProcessor = new MemoryProcessor()
        const relevantMemories = await memoryProcessor.searchRelevantMemories(query, processorConfig, limit)

        if (relevantMemories?.length > 0) {
          // console.log('ðŸ§  [memorySearchTool] Found memories:', relevantMemories.length)
          return relevantMemories
        }
        return []
      } catch (error) {
        // console.error('ðŸ§  [memorySearchTool] Error:', error)
        return []
      }
    }
  })
}

// æ–¹æ¡ˆ4: ä¸ºç¬¬äºŒä¸ªå·¥å…·ä¹Ÿä½¿ç”¨ç±»åž‹æ–­è¨€
type MessageRole = 'user' | 'assistant' | 'system'
type MessageType = {
  content: string
  role: MessageRole
}
type MemorySearchWithExtractionInput = {
  userMessage: MessageType
  lastAnswer?: MessageType
}

/**
 * ðŸ§  æ™ºèƒ½è®°å¿†æœç´¢å·¥å…·ï¼ˆå¸¦ä¸Šä¸‹æ–‡æå–ï¼‰
 * ä»Žç”¨æˆ·æ¶ˆæ¯å’Œå¯¹è¯åŽ†å²ä¸­è‡ªåŠ¨æå–å…³é”®è¯è¿›è¡Œè®°å¿†æœç´¢
 */
export const memorySearchToolWithExtraction = (assistant: Assistant) => {
  return tool({
    name: 'memory_search_with_extraction',
    description: 'Search memories with automatic keyword extraction from conversation context',
    inputSchema: z.object({
      userMessage: z.object({
        content: z.string().describe('The main content of the user message'),
        role: z.enum(['user', 'assistant', 'system']).describe('Message role')
      }),
      lastAnswer: z
        .object({
          content: z.string().describe('The main content of the last assistant response'),
          role: z.enum(['user', 'assistant', 'system']).describe('Message role')
        })
        .optional()
    }) as z.ZodSchema<MemorySearchWithExtractionInput>,
    execute: async ({ userMessage }) => {
      // console.log('ðŸ§  [memorySearchToolWithExtraction] Processing:', { userMessage, lastAnswer })

      try {
        const globalMemoryEnabled = selectGlobalMemoryEnabled(store.getState())
        if (!globalMemoryEnabled || !assistant.enableMemory) {
          return {
            extractedKeywords: 'Memory search disabled',
            searchResults: []
          }
        }

        const memoryConfig = selectMemoryConfig(store.getState())
        if (!memoryConfig.llmApiClient || !memoryConfig.embedderApiClient) {
          // console.warn('Memory search skipped: embedding or LLM model not configured')
          return {
            extractedKeywords: 'Memory models not configured',
            searchResults: []
          }
        }

        // ðŸ” ä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯å†…å®¹ä½œä¸ºæœç´¢å…³é”®è¯
        const content = userMessage.content

        if (!content) {
          return {
            extractedKeywords: 'No content to search',
            searchResults: []
          }
        }

        const currentUserId = selectCurrentUserId(store.getState())
        const processorConfig = MemoryProcessor.getProcessorConfig(memoryConfig, assistant.id, currentUserId)

        const memoryProcessor = new MemoryProcessor()
        const relevantMemories = await memoryProcessor.searchRelevantMemories(
          content,
          processorConfig,
          5 // Limit to top 5 most relevant memories
        )

        if (relevantMemories?.length > 0) {
          // console.log('ðŸ§  [memorySearchToolWithExtraction] Found memories:', relevantMemories.length)
          return {
            extractedKeywords: content,
            searchResults: relevantMemories
          }
        }

        return {
          extractedKeywords: content,
          searchResults: []
        }
      } catch (error) {
        // console.error('ðŸ§  [memorySearchToolWithExtraction] Error:', error)
        return {
          extractedKeywords: 'Search failed',
          searchResults: []
        }
      }
    }
  })
}
export type MemorySearchToolInput = InferToolInput<ReturnType<typeof memorySearchTool>>
export type MemorySearchToolOutput = InferToolOutput<ReturnType<typeof memorySearchTool>>
export type MemorySearchToolWithExtractionOutput = InferToolOutput<ReturnType<typeof memorySearchToolWithExtraction>>
